{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865cf3c-bea2-43de-a738-18c4c8f0e820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to transform XES to PKL\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "# from dateutil.parser import parse\n",
    "from tqdm import tqdm\n",
    "import pm4py\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "folder_path = 'data'  # Replace with the path to your folder\n",
    "\n",
    "# Use glob to get a list of all .xes files in the folder\n",
    "xes_files = glob.glob(os.path.join(folder_path, '*.xes'))\n",
    "\n",
    "# Print the list of .xes files\n",
    "for xes_file in xes_files:\n",
    "    file_name = os.path.basename(xes_file)\n",
    "    print(file_name)\n",
    "    \n",
    "\n",
    "    \n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "do_display=True\n",
    "\n",
    "def build_entity_sequence(df_input,entity_colname,obs_colname,time_colname,method_time):\n",
    "    \"\"\"Crée un jeu de données de séquence, a la maille entité-> passage de la maille \"obs/entité\" a la maille \"entité\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "        La dataframe utilisée\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    df_seq : dataframe\n",
    "        jeu de données de séquences à la maille entité\n",
    "    \"\"\" \n",
    "    \n",
    "    def create_obs_sequence_for_entity(df_indiv): # crée la séquence d'événements pour l'entité\n",
    "        seq_entite = []\n",
    "        for j in range(len(df_indiv)):\n",
    "            seq_entite.append(df_indiv.loc[j, obs_colname])\n",
    "        return seq_entite\n",
    "\n",
    "    def create_interval_sequence_for_entity(df_indiv): # utilise les intervalles de temps dans la séquence timestamps\n",
    "        interv_seq_entite = []\n",
    "        for j in range(len(df_indiv)):\n",
    "            if j==len(df_indiv)-1:\n",
    "                interv_seq_entite.append(0.0)\n",
    "            else:\n",
    "                interv_seq_entite.append(df_indiv.loc[j+1, time_colname]-df_indiv.loc[j, time_colname])\n",
    "        return interv_seq_entite\n",
    "    \n",
    "    def create_timestamp_sequence_for_entity(df_indiv): # utilise les timestamps dans la séquence timestamps\n",
    "        interv_seq_entite = []\n",
    "        for index, row in df_indiv.iterrows():\n",
    "            interv_seq_entite.append(row[\"date\"])\n",
    "        return interv_seq_entite\n",
    "    def create_empty_time_sequence_for_entity(df_indiv): # remplace la séquence de timestamps par des 0\n",
    "        interv_seq_entite = []\n",
    "        for index, row in df_indiv.iterrows():\n",
    "            interv_seq_entite.append(0)\n",
    "        return interv_seq_entite\n",
    "    df=df_input.copy()\n",
    "    min_date = df['date'].min()\n",
    "    df['date']=(df.date-min_date).dt.total_seconds()/3600 # timestamp to number of seconds since first obs\n",
    "    \n",
    "    dicCol = {x:y for x,y in df.groupby(entity_colname)}\n",
    "    \n",
    "    # filter short sequences\n",
    "    min_length = 1\n",
    "    dicCol = {key: df for key, df in dicCol.items() if len(df) >= min_length} \n",
    "    # print(len(dicCol))\n",
    "    \n",
    "    list_seq = []\n",
    "    columns = ['Entite', 'Obs_seq', 'Intervals_seq']\n",
    "    \n",
    "    for entite, df_entite in tqdm(dicCol.items()): \n",
    "        \n",
    "        df_entite = df_entite.sort_values(by=['date'], ignore_index=True)\n",
    "        \n",
    "        seq_entite = create_obs_sequence_for_entity(df_entite)\n",
    "        \n",
    "        if method_time==\"timestamp\":\n",
    "            seq_entite_time = create_timestamp_sequence_for_entity(df_entite)\n",
    "            \n",
    "        elif method_time==\"interval\":\n",
    "            seq_entite_time = create_interval_sequence_for_entity(df_entite)\n",
    "            \n",
    "        elif method_time==\"no_timestamp\":\n",
    "            seq_entite_time = create_empty_time_sequence_for_entity(df_entite)\n",
    "            \n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        list_seq.append([entite, seq_entite, seq_entite_time])\n",
    "\n",
    "    # Créez le DataFrame une fois que toutes les données sont prêtes\n",
    "    df_seq_entite = pd.DataFrame(list_seq, columns=columns)\n",
    "    return df_seq_entite\n",
    "\n",
    "def get_variable_frequency_stats(data,col_name):\n",
    "    min_date=data['date'].min()\n",
    "    datax = data[col_name].value_counts().sort_index()\n",
    "    datay = pd.DataFrame({\n",
    "      'state': datax.index,\n",
    "      'Frequency': datax.values,\n",
    "      'Percent': ((datax.values/datax.values.sum())*100).round(2),\n",
    "      'Cumulative Frequency': datax.values.cumsum(),\n",
    "      'Cumulative Percent': ((datax.values.cumsum()/datax.values.sum())*100)\\\n",
    "    .round(2)\n",
    "    })\n",
    "    display(datay.sort_values(by=['Frequency']))\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "do_display=True\n",
    "list_dataset = [\n",
    "    \n",
    "    \"env_permit\",\n",
    "    \"Helpdesk\",\n",
    "    \"nasa\",\n",
    "    \"SEPSIS\",\n",
    "    \"BPI_Challenge_2012\",\n",
    "    \"BPI_Challenge_2012_A\",\n",
    "    \"BPI_Challenge_2012_Complete\",\n",
    "    \"BPI_Challenge_2012_O\",\n",
    "    \"BPI_Challenge_2012_W\",\n",
    "    \"BPI_Challenge_2012_W_Complete\",\n",
    "    \"BPI_Challenge_2013_closed_problems\",\n",
    "    \"bpi_challenge_2013_incidents\",\n",
    "    \"BPI Challenge 2017\",\n",
    "    \"BPI_Challenge_2019\",\n",
    "\n",
    "    # \"BPIC15_1\",\n",
    "#     \"BPIC15_2\",\n",
    "#     \"BPIC15_3\",\n",
    "#     \"BPIC15_4\",\n",
    "#     \"BPIC15_5\",\n",
    "#     \"Hospital_log\"\n",
    "]\n",
    "list_dataset = [\"DATA_MCF_1an_prest\"]\n",
    "\n",
    "for file_name in list_dataset: \n",
    "    print(\"======================================\")\n",
    "    print(\"-------- Dataset: \"+file_name)\n",
    "    print(\"======================================\")\n",
    "    data = pm4py.read_xes('data/%s.xes'%(file_name))\n",
    "    data = pm4py.convert_to_dataframe(data)[[\"case:concept:name\",\"time:timestamp\",\"concept:name\"]]\n",
    "    data.rename(columns={'time:timestamp':'date'}, inplace=True)\n",
    "    data.rename(columns={'case:concept:name':'entity'}, inplace=True)\n",
    "    data.rename(columns={'concept:name':'type'}, inplace=True)\n",
    "    \n",
    "    if do_display: display(data.head(10))\n",
    "    data=data[data['entity'].notnull()]\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "    data['entity'] = pd.factorize(data['entity'])[0]\n",
    "    data['type'] = pd.factorize(data['type'])[0]\n",
    "    \n",
    "    if do_display: print('df_entity_seq_interval')\n",
    "    df_entity_seq_interval     = build_entity_sequence(data,'entity',\"type\",\"date\",method_time=\"interval\") # appel de la fonction ci-dessus avec le param_tre \"intervalles\"\n",
    "    if do_display: display(df_entity_seq_interval.head(10))\n",
    "    df_entity_seq_interval.to_pickle(\"data/%s.pkl\"%(file_name))\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0698e6-816c-4e90-aaee-191315580c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
